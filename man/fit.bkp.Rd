% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fitBKP.R
\name{fit.BKP}
\alias{fit.BKP}
\title{Fit a Beta Kernel Process (BKP) Model for Binomial Observations}
\usage{
fit.BKP(
  data,
  X = NULL,
  y = NULL,
  m = NULL,
  alpha0 = 1,
  beta0 = 1,
  Xbounds = NULL,
  kernel = c("gaussian", "matern52", "matern32"),
  loss = c("brier", "NLML")
)
}
\arguments{
\item{data}{Optional data frame containing covariates \code{X}, observations \code{y}, and counts \code{m}
in the first \eqn{d}, \eqn{d+1}, and \eqn{d+2} columns, respectively.}

\item{X}{Covariate matrix of size \eqn{n \times d}. Ignored if \code{data} is provided.}

\item{y}{Vector of observed successes. Must be numeric with length equal to number of rows in \code{X}.}

\item{m}{Vector of binomial counts (trials). Must be numeric, positive, and same length as \code{y}.}

\item{alpha0}{Prior shape parameter (scalar or vector of length \eqn{n}) for the beta distribution.}

\item{beta0}{Prior shape parameter (scalar or vector of length \eqn{n}) for the beta distribution.}

\item{Xbounds}{Optional \eqn{d \times 2} matrix defining lower and upper bounds for each input dimension
(used for normalization). Defaults to \code{[0,1]^d}.}

\item{kernel}{Character string specifying the kernel function to use: one of \code{"gaussian"},
\code{"matern52"}, or \code{"matern32"}.}

\item{loss}{Loss function to be minimized during hyperparameter tuning. Choose between \code{"brier"}
(default) and \code{"NLML"} (negative log marginal likelihood).}
}
\value{
An object of class \code{"BKP"} containing:
\item{bestTheta}{Optimal kernel parameters (length \eqn{d}).}
\item{kernel}{Kernel type used.}
\item{loss}{Loss function used.}
\item{minLoss}{Minimum achieved loss.}
\item{X}{Original (unnormalized) design matrix.}
\item{Xnorm}{Normalized design matrix (scaled to \code{[0,1]^d}).}
\item{Xbounds}{\eqn{d \times 2} matrix defining lower and upper bounds for each input dimension.}
\item{y}{Observed successes.}
\item{m}{Binomial counts.}
\item{alpha0, beta0}{Prior parameters used.}
\item{alpha.n, beta.n}{Posterior parameters (vector).}
}
\description{
Fits a Beta Kernel Process model for binomial data, estimating latent functions
representing Beta distribution parameters using kernel smoothing.
}
\details{
The function fits the BKP model by optimizing kernel hyperparameters using multi-start
local optimization. Inputs are first normalized to the \eqn{[0,1]^d} space defined by \code{Xbounds}.
The kernel matrix is computed with optimized parameters, and posterior Beta parameters
\eqn{\alpha_n} and \eqn{\beta_n} are computed by smoothing the observed successes \eqn{y}
and failures \eqn{m - y} with the kernel matrix:
\deqn{
\alpha_n = \alpha_0 + K \cdot y, \quad
\beta_n = \beta_0 + K \cdot (m - y)
}
where \eqn{K} is the kernel matrix evaluated at normalized inputs.
}
\examples{
\dontrun{
### 1D
set.seed(123)
n <- 100
Xbounds <- matrix(c(-2,2), nrow=1)
x <- seq(-2, 2, length = n)
true_pi <- (1 + exp(-x^2) * cos(10 * (1 - exp(-x)) / (1 + exp(-x)))) / 2
m <- sample(100, n, replace = TRUE)
y <- rbinom(n, size = m, prob = true_pi)
df <- data.frame(x = x, y = y, m = m)
xx = matrix(seq(-2, 2, length = 100), ncol=1) #new data points
model <- fit.BKP(df, Xbounds=Xbounds)
head(predict(model,xx))
plot(model)
print(model)
summary(model)

### 2D
set.seed(123)
n <- 100
f <- function(X) {
  if(is.null(nrow(X))) X <- matrix(X, nrow=1)
  m <- 8.6928
  s <- 2.4269
  x1 <- 4*X[,1]- 2
  x2 <- 4*X[,2]- 2
  a <- 1 + (x1 + x2 + 1)^2 *
    (19- 14*x1 + 3*x1^2- 14*x2 + 6*x1*x2 + 3*x2^2)
  b <- 30 + (2*x1- 3*x2)^2 *
    (18- 32*x1 + 12*x1^2 + 48*x2- 36*x1*x2 + 27*x2^2)
  f <- log(a*b)
  f <- (f- m)/s
  return(f) }
Xbounds <- matrix(c(0, 0, 1, 1), nrow = 2)
library(tgp)
x <- lhs(n = n, rect = Xbounds)
true_pi <- pnorm(f(x))
m <- sample(100, n, replace = TRUE)
y <- rbinom(n, size = m, prob = true_pi)
df <- data.frame(x = x, y = y, m = m)
xx1 <- seq(Xbounds[1,1], Xbounds[1,2], length.out = 100)
xx2 <- seq(Xbounds[2,1], Xbounds[2,2], length.out = 100)
xx <- expand.grid(xx1 = xx1, xx2 = xx2)
#plot the true probability
true_pi <- matrix(pnorm(f(xx)), nrow = length(xx1), ncol = length(xx2))
image(xx1, xx2, true_pi, xlab ="X1", ylab ="X2",
                main = "True Probability",
                col = hcl.colors(100, "viridis"))
contour(xx1, xx2, true_pi, add = TRUE, col = "black")
model <- fit.BKP(df)
head(predict(model,xx))
plot(model)
print(model)
summary(model)
}

}
\author{
Jiangyan Zhao, Kunhai Qing, Jin Xu
}
